{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Part 1 Extract, transform, load, snow pit and transect data\n",
    "[Josh King](https://github.com/kingjml), *CPS/CRD/ECCC*, 2021  \n",
    "[Benoit Montpetit](https://github.com/ecccben), *CPS/CRD/ECCC*, 2024  \n",
    "[Mike Brady](https://github.com/m9brady), *CPS/CRD/ECCC*, 2024\n",
    "\n",
    "This notebook provides data extraction, transformation and loading procedures for field data collected during the 2018-2019 TVCSnow campaign. The full dataset contains measurements which exceed the discussed material within this paper (e.g. 3 observation periods, where as only 1 is discussed in text).\n",
    "\n",
    "Data at all sites (both static and roving) comes from 4 sources which are imported and prepared for analysis. We create reference SSA and density profiles from the imported snow pit and IceCube data. All data are UTM8N georefereced (EPSG 32608). Finalized datasets are exported to be used in further analysis steps. Second, we generate products to represent the snowpack at each site for further analysis and modeling. Imported snow pits are in the standard ECCC format and are read with the [snow pit parser](https://github.com/kingjml/tvc-snowpit-parser) developed along with [Mike Brady](https://github.com/m9brady) and [Ben Montpetit](https://github.com/ECCCBen).\n",
    "\n",
    "\n",
    "Output of the workbook are science ready snow products for the TVC domain in pickle format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish path from notebook\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Community imports\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "from shapely.geometry import mapping\n",
    "from shapely.wkt import loads as wkt_load\n",
    "\n",
    "# Plot imports and settings\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib\n",
    "\n",
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 22}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "plt.rcParams[\"axes.labelsize\"] = 22\n",
    "plt.rcParams[\"axes.labelweight\"] = 'bold'\n",
    "plt.rcParams['xtick.labelsize']=16\n",
    "plt.rcParams['ytick.labelsize']=16\n",
    "\n",
    "# ECCC imports\n",
    "import constants\n",
    "import tvcfunc\n",
    "from snowpit_datasheet_parser import SnowPitSheet\n",
    "\n",
    "# Paths to external files and constants\n",
    "ext_file_list = [constants.VEG_TYPE_FILE, constants.VEG_HEIGHT_FILE, constants.DTM_ELV_FILE]\n",
    "ext_file_var = ['veg_type', 'veg_height', 'dtm_elv', 'dtm_slope']\n",
    "site_dirs = Path('../Data/Site')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl site directories and match data sources\n",
    "\n",
    "This section crawls our field data and generates metadata. Input has been structured into site folders. The following datasets are evaluated:\n",
    "\n",
    "1. **mp_files** - Magnaprobe Snow Depth - ECCC Standardized Excel Format\n",
    "2. **pit_files** - Standard Snow Pits - ECCC Standardized Excel Format\n",
    "3. **ssa_files** - IceCube SSA - ECCC Standardized Excel Format\n",
    "4. **pnt_files** -  SnowMicroPen Penetration Force - SLF PNT Format\n",
    "\n",
    "Output is a validated list of field datasets available for each site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_meta = tvcfunc.gen_site_meta(site_dirs)\n",
    "site_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>site</th>\n",
    "      <th>pnt_files</th>\n",
    "      <th>smp_meta</th>\n",
    "      <th>pit_files</th>\n",
    "      <th>ssa_files</th>\n",
    "      <th>mp_files</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>RS01</td>\n",
    "      <td>[Data\\Site\\RS01\\S34M2527.pnt, Data\\Site\\RS01\\S...</td>\n",
    "      <td>[Data\\Site\\RS01\\SMP_131118_RS01.csv]</td>\n",
    "      <td>[Data\\Site\\RS01\\PIT_131118_RS01.xlsx]</td>\n",
    "      <td>[Data\\Site\\RS01\\SSA_131118_RS01.csv]</td>\n",
    "      <td>[Data\\Site\\RS01\\MP_131118_RS01.xlsx]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>RS02</td>\n",
    "      <td>[Data\\Site\\RS02\\S34M2546.pnt, Data\\Site\\RS02\\S...</td>\n",
    "      <td>[Data\\Site\\RS02\\SMP_131118_RS02.csv]</td>\n",
    "      <td>[Data\\Site\\RS02\\PIT_131118_RS02.xlsx]</td>\n",
    "      <td>[Data\\Site\\RS02\\SSA_131118_RS02.csv]</td>\n",
    "      <td>[Data\\Site\\RS02\\MP_131118_RS02.xlsx]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>RS03</td>\n",
    "      <td>[Data\\Site\\RS03\\S34M2622.pnt, Data\\Site\\RS03\\S...</td>\n",
    "      <td>[Data\\Site\\RS03\\SMP_141118_RS03.csv]</td>\n",
    "      <td>[Data\\Site\\RS03\\PIT_141118_RS03.xlsx]</td>\n",
    "      <td>[Data\\Site\\RS03\\SSA_141118_RS03.csv]</td>\n",
    "      <td>[Data\\Site\\RS03\\MP_141118_RS03.xlsx]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>RS04</td>\n",
    "      <td>[Data\\Site\\RS04\\S34M2640.pnt, Data\\Site\\RS04\\S...</td>\n",
    "      <td>[Data\\Site\\RS04\\SMP_141118_RS04.csv]</td>\n",
    "      <td>[Data\\Site\\RS04\\PIT_141118_RS04.xlsx]</td>\n",
    "      <td>[Data\\Site\\RS04\\SSA_141118_RS04.csv]</td>\n",
    "      <td>[Data\\Site\\RS04\\MP_141118_RP04.xlsx]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>RS05</td>\n",
    "      <td>[Data\\Site\\RS05\\S34M2660.pnt, Data\\Site\\RS05\\S...</td>\n",
    "      <td>[Data\\Site\\RS05\\SMP_151118_RS05.csv]</td>\n",
    "      <td>[Data\\Site\\RS05\\PIT_151118_RS05.xlsx]</td>\n",
    "      <td>[Data\\Site\\RS05\\SSA_151118_RS05.csv]</td>\n",
    "      <td>[Data\\Site\\RS05\\MP_151118_RS05.xlsx]</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL snow pit reference data\n",
    "This section loads all of the snow pit sheets and pulls meta data to create geospatial dataframe projected in UTM8N.\n",
    "\n",
    "I then extract the density, ssa, and temperature profiles from each snow pit to generate and validate reference datasets. Each profile includes the associated grain type as well as relative height from the air-snow interface. Temperature profiles include tagging for the media type of the measurement.\n",
    "\n",
    "I use the [SnowPitSheet library](https://github.com/kingjml/tvc-snowpit-parser) to read in our ECCC CPS style pit sheets. QA level metadata are provided in pit_meta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the snow pit data and create a geospatial dataframe\n",
    "pit_files = site_meta['pit_files'].map(lambda x: x[0]).values\n",
    "pit_data = [SnowPitSheet(pit) for pit in pit_files]\n",
    "pit_df = [pd.DataFrame.from_dict(pit.meta, orient='index').transpose() for pit in pit_data]\n",
    "pit_df = pd.concat(pit_df, axis=0)\n",
    "pit_df['file_path'] = pit_files\n",
    "pit_gdf = gpd.GeoDataFrame(data=pit_df.drop('geometry', axis=1), \n",
    "                           geometry=pit_df['geometry'].apply(wkt_load), \n",
    "                           crs=constants.CRS_WGS84)\n",
    "\n",
    "pit_meta = pit_gdf.to_crs(constants.CRS_UTM8N).reset_index(drop=True)\n",
    "pit_meta['timestamp'] = pd.to_datetime(pit_meta['timestamp']) \n",
    "pit_meta['site'] =pit_meta['pit_id'].str.replace('RP', 'RS', regex=True)\n",
    "\n",
    "# Tag the campaign\n",
    "pit_meta.loc[pit_meta['site'].isin(constants.TVC01), 'campaign'] = 'TVC01'\n",
    "pit_meta.loc[pit_meta['site'].isin(constants.TVC02), 'campaign'] = 'TVC02'\n",
    "pit_meta.loc[pit_meta['site'].isin(constants.TVC03), 'campaign'] = 'TVC03'\n",
    "pit_meta.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>location</th>\n",
    "      <th>timestamp</th>\n",
    "      <th>surveyors</th>\n",
    "      <th>site</th>\n",
    "      <th>pit_id</th>\n",
    "      <th>slope</th>\n",
    "      <th>total_depth</th>\n",
    "      <th>utm_zone</th>\n",
    "      <th>comments</th>\n",
    "      <th>weather</th>\n",
    "      <th>...</th>\n",
    "      <th>wind_1</th>\n",
    "      <th>wind_2</th>\n",
    "      <th>ground_condition</th>\n",
    "      <th>soil_moisture</th>\n",
    "      <th>ground_roughness</th>\n",
    "      <th>ground_vegetation</th>\n",
    "      <th>tree_canopy</th>\n",
    "      <th>file_path</th>\n",
    "      <th>geometry</th>\n",
    "      <th>campaign</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>TVC 2018</td>\n",
    "      <td>2018-11-13 09:48:00</td>\n",
    "      <td>Josh, Ben</td>\n",
    "      <td>RS01</td>\n",
    "      <td>RP01</td>\n",
    "      <td>Flat</td>\n",
    "      <td>34.5</td>\n",
    "      <td>8N</td>\n",
    "      <td>Comments/Notes/Indicate co-located measurements:</td>\n",
    "      <td>First roving site. Located at site waypoint #....</td>\n",
    "      <td>...</td>\n",
    "      <td>None</td>\n",
    "      <td>None</td>\n",
    "      <td>None</td>\n",
    "      <td>None</td>\n",
    "      <td>None</td>\n",
    "      <td>{}</td>\n",
    "      <td>None</td>\n",
    "      <td>Data\\Site\\RS01\\PIT_131118_RS01.xlsx</td>\n",
    "      <td>POINT (561402.426 7627347.290)</td>\n",
    "      <td>TVC01</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>TVC 2018</td>\n",
    "      <td>2018-11-13 11:53:00</td>\n",
    "      <td>Josh, Ben</td>\n",
    "      <td>RS02</td>\n",
    "      <td>RP02</td>\n",
    "      <td>Flat</td>\n",
    "      <td>28.0</td>\n",
    "      <td>8N</td>\n",
    "      <td>Comments/Notes/Indicate co-located measurements:</td>\n",
    "      <td>Located on a plateau. AT = -23, winds at 3 m/s...</td>\n",
    "      <td>...</td>\n",
    "      <td>None</td>\n",
    "      <td>None</td>\n",
    "      <td>None</td>\n",
    "      <td>None</td>\n",
    "      <td>None</td>\n",
    "      <td>{}</td>\n",
    "      <td>None</td>\n",
    "      <td>Data\\Site\\RS02\\PIT_131118_RS02.xlsx</td>\n",
    "      <td>POINT (560862.323 7627725.511)</td>\n",
    "      <td>TVC01</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "<p>2 rows × 22 columns</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reference density, SSA and temperature  profiles for each site\n",
    "ref_rho = pd.DataFrame(); ref_ssa = pd.DataFrame(); ref_temp = pd.DataFrame()\n",
    "for s_dix, s_meta in site_meta.iterrows():  \n",
    "    pit_path = s_meta['pit_files'][0] # Only 1 pit per site for TVC\n",
    "    ssa_path = s_meta['ssa_files'][0] # TODO: deal with multiple SSA files\n",
    "    ref_rho = pd.concat([ref_rho,pd.DataFrame(tvcfunc.load_ref_rho(pit_path).assign(site = s_meta['site']))], ignore_index = True)\n",
    "    ref_ssa = pd.concat([ref_ssa,pd.DataFrame(tvcfunc.load_ref_ssa(ssa_path, pit_path).assign(site = s_meta['site']))], ignore_index = True)\n",
    "    ref_temp = pd.concat([ref_temp,pd.DataFrame(tvcfunc.load_ref_temperature(pit_path).assign(site = s_meta['site']))], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example snow pit data\n",
    "The next two plots show observed density and SSA at (1) a single location and (2) for all snow pits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example snowpit of reference information\n",
    "site_select = 'SM02'\n",
    "dens = ref_rho.loc[ref_rho['site'] == site_select]\n",
    "ssa = ref_ssa.loc[ref_ssa['site'] == site_select]\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax2 = ax1.twiny()\n",
    "lns1 = ax1.plot(ssa['ssa'], ssa['height']/1000, marker = 'o', color = 'k', label = 'SSA')\n",
    "lns2 = ax2.plot(dens['density'], dens['height']/1000, marker = 'o', color = 'teal', label = 'Density')\n",
    "ax1.set_xlim(0,ssa['ssa'].max()+5)\n",
    "ax1.set_ylim(0, ssa['height'].max()/1000 + 0.055)\n",
    "ax2.set_xlim(75,dens['height'].max())\n",
    "ax1.set_xlabel('SSA $m^2\\\\cdot kg^{-1}$')\n",
    "ax1.set_ylabel('Height above ground (mm)')\n",
    "ax2.set_xlabel('$\\\\rho_{snow} (kg\\\\cdot m^{-3})$')\n",
    "\n",
    "# added these three lines\n",
    "lns = lns1+lns2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax1.legend(lns, labs, loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../Figures/Part_1_ETL_Field_Fig1.png\" height=\"500px\"></center>\n",
    "\n",
    "<center>Figure: Example of a snow density and SSA profile</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit data to only January campaign\n",
    "ref_rho_tvc2 = ref_rho[ref_rho['site'].isin(constants.TVC02)]\n",
    "ref_ssa_tvc2 = ref_ssa[ref_ssa['site'].isin(constants.TVC02)]\n",
    "\n",
    "# Layer colours based on international classification of snow\n",
    "colors = {'N':'#969696', 'F':'#ADD8E6', 'H':'#0000FF', 'R':'#FFB6C1', 'M':'grey'}\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(15,10))\n",
    "ax1.scatter(ref_rho_tvc2['density'],ref_rho_tvc2['height']/1000, s = 10, alpha = 1, c=ref_rho_tvc2['grain_type'].map(colors))\n",
    "ax2.scatter(ref_ssa_tvc2['ssa'],ref_ssa_tvc2['height']/1000, s = 10, alpha = 1, c=ref_ssa_tvc2['grain_type'].map(colors))\n",
    "ax2.set_xlim(0, 70)\n",
    "ax2.set_ylim(0, 0.75)\n",
    "ax2.set_xlabel('SSA [m$\\mathregular{^2}$ kg$\\mathregular{^{-1}}$]')\n",
    "ax1.set_ylabel('Height above surface [m]')\n",
    "ax1.set_xlabel('Density [kg m$\\mathregular{^{-3}}$]')\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label='Rounded',\n",
    "                          markerfacecolor='#FFB6C1', markersize=10),\n",
    "                  Line2D([0], [0], marker='o', color='w', label='Faceted',\n",
    "                          markerfacecolor='#ADD8E6', markersize=10),\n",
    "                  Line2D([0], [0], marker='o', color='w', label='Hoar',\n",
    "                          markerfacecolor='#0000FF', markersize=10),\n",
    "                  Line2D([0], [0], marker='o', color='w', label='Mixed',\n",
    "                          markerfacecolor='grey', markersize=10)]\n",
    "ax2.legend(handles=legend_elements, fontsize=12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../Figures/Part_1_ETL_Field_Fig2.png\" height=\"500px\"></center>\n",
    "\n",
    "<center>Figure: Example of a snow density and SSA profile color coded by grain type</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ssa_tvc2.groupby('grain_type')['ssa'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>count</th>\n",
    "      <th>mean</th>\n",
    "      <th>std</th>\n",
    "      <th>min</th>\n",
    "      <th>25%</th>\n",
    "      <th>50%</th>\n",
    "      <th>75%</th>\n",
    "      <th>max</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>grain_type</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>F</th>\n",
    "      <td>59.0</td>\n",
    "      <td>25.180908</td>\n",
    "      <td>8.250971</td>\n",
    "      <td>12.911707</td>\n",
    "      <td>18.891815</td>\n",
    "      <td>23.762626</td>\n",
    "      <td>28.141087</td>\n",
    "      <td>46.787239</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>H</th>\n",
    "      <td>133.0</td>\n",
    "      <td>13.374954</td>\n",
    "      <td>2.221366</td>\n",
    "      <td>9.901494</td>\n",
    "      <td>12.098719</td>\n",
    "      <td>13.067053</td>\n",
    "      <td>13.944551</td>\n",
    "      <td>24.251712</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>M</th>\n",
    "      <td>54.0</td>\n",
    "      <td>40.384020</td>\n",
    "      <td>13.607262</td>\n",
    "      <td>13.037687</td>\n",
    "      <td>30.130222</td>\n",
    "      <td>36.398524</td>\n",
    "      <td>51.564161</td>\n",
    "      <td>72.452065</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>R</th>\n",
    "      <td>2.0</td>\n",
    "      <td>45.078542</td>\n",
    "      <td>3.012478</td>\n",
    "      <td>42.948398</td>\n",
    "      <td>44.013470</td>\n",
    "      <td>45.078542</td>\n",
    "      <td>46.143613</td>\n",
    "      <td>47.208685</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_rho_tvc2.groupby('grain_type')['density'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>count</th>\n",
    "      <th>mean</th>\n",
    "      <th>std</th>\n",
    "      <th>min</th>\n",
    "      <th>25%</th>\n",
    "      <th>50%</th>\n",
    "      <th>75%</th>\n",
    "      <th>max</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>grain_type</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>F</th>\n",
    "      <td>58.0</td>\n",
    "      <td>301.413788</td>\n",
    "      <td>65.989906</td>\n",
    "      <td>153.0</td>\n",
    "      <td>246.00</td>\n",
    "      <td>299.0</td>\n",
    "      <td>364.25</td>\n",
    "      <td>410.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>H</th>\n",
    "      <td>128.0</td>\n",
    "      <td>220.632812</td>\n",
    "      <td>29.218931</td>\n",
    "      <td>166.0</td>\n",
    "      <td>208.75</td>\n",
    "      <td>218.0</td>\n",
    "      <td>229.00</td>\n",
    "      <td>369.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>M</th>\n",
    "      <td>57.0</td>\n",
    "      <td>325.333344</td>\n",
    "      <td>81.980904</td>\n",
    "      <td>116.0</td>\n",
    "      <td>265.00</td>\n",
    "      <td>334.0</td>\n",
    "      <td>403.00</td>\n",
    "      <td>438.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>R</th>\n",
    "      <td>2.0</td>\n",
    "      <td>228.000000</td>\n",
    "      <td>1.414214</td>\n",
    "      <td>227.0</td>\n",
    "      <td>227.50</td>\n",
    "      <td>228.0</td>\n",
    "      <td>228.50</td>\n",
    "      <td>229.0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magnaprobe snow depth data\n",
    "ETL for ECCC standard magnaprobe files to a generate geospatial dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the magnaprobe data and create a geospatial dataframe\n",
    "mp_data = pd.DataFrame()\n",
    "mp_files = site_meta['mp_files'].map(lambda x: x[0]).values\n",
    "mp_data = [pd.read_excel(mp).assign(site = site) for site, mp in zip(site_meta['site'].values, mp_files)]\n",
    "mp_data = pd.concat(mp_data, axis=0)\n",
    "mp_data = mp_data.drop(columns=['Counter','Unit'])\n",
    "mp_data.columns = ['timestamp', 'depth', 'lat', 'lon', 'site']\n",
    "mp_data = mp_data.loc[(mp_data['depth'] > 1 )| (mp_data['depth'] < 119)] # Drop marker measurements\n",
    "\n",
    "mp_gdf = gpd.GeoDataFrame(mp_data, \n",
    "                          geometry=gpd.points_from_xy(mp_data.lon, mp_data.lat), \n",
    "                          crs = constants.CRS_WGS84)\n",
    "mp_utm = mp_gdf.to_crs(constants.CRS_UTM8N)\n",
    "\n",
    "mp_utm.loc[mp_utm['site'].isin(constants.TVC01), 'campaign'] = 'TVC01'\n",
    "mp_utm.loc[mp_utm['site'].isin(constants.TVC02), 'campaign'] = 'TVC02'\n",
    "mp_utm.loc[mp_utm['site'].isin(constants.TVC03), 'campaign'] = 'TVC03'\n",
    "\n",
    "# This flags instances where the Magnaprobe RTC battery failed\n",
    "time_fix, rtc_fail = tvcfunc.rtc_check_mp(mp_utm['timestamp'])\n",
    "mp_utm = mp_utm.assign(timestamp = time_fix, rtc_fail = rtc_fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two plots show (1) the seasonal distrobutions of snows depth across all sites and (2) locations of the snow depths seperated by campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0,120, 2)\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(15,10))\n",
    "ax1.hist(mp_utm.loc[mp_utm['campaign'] == 'TVC01']['depth'].values, \n",
    "         density=True, bins=bins, label = 'TVC-1', color = 'GREY')\n",
    "ax2.hist(mp_utm.loc[mp_utm['campaign'] == 'TVC02']['depth'].values, \n",
    "         density=True, bins=bins, label = 'TVC-2', color = 'GREY') \n",
    "ax3.hist(mp_utm.loc[mp_utm['campaign'] == 'TVC03']['depth'].values, \n",
    "         density=True, bins=bins, label = 'TVC-3', color = 'GREY') \n",
    "\n",
    "ax1.set_title('TVC1 - Nov 2018')\n",
    "ax2.set_title('TVC2 - Jan 2019')\n",
    "ax3.set_title('TVC3 - Mar 2019')\n",
    "ax2.set_xlabel('Snow Depth [cm]')\n",
    "ax1.set_ylabel('Probability [%]')\n",
    "\n",
    "\n",
    "mean_1 = mp_utm.loc[mp_utm['campaign'] == 'TVC01']['depth'].mean()\n",
    "mean_2 = mp_utm.loc[mp_utm['campaign'] == 'TVC02']['depth'].mean()\n",
    "mean_3 = mp_utm.loc[mp_utm['campaign'] == 'TVC03']['depth'].mean()\n",
    "\n",
    "ax1.axvline(x=mean_1, color='r', linestyle='--')\n",
    "ax2.axvline(x=mean_2, color='r', linestyle='--')\n",
    "ax3.axvline(x=mean_3, color='r', linestyle='--')\n",
    "\n",
    "ax1.set_xlim(0,100)\n",
    "ax2.set_xlim(0,100)\n",
    "ax3.set_xlim(0,100)\n",
    "\n",
    "#f.savefig('Figures/site_magnaprobe_depth.jpg', dpi = 300)\n",
    "\n",
    "mp_utm.groupby('campaign')['depth'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>count</th>\n",
    "      <th>mean</th>\n",
    "      <th>std</th>\n",
    "      <th>min</th>\n",
    "      <th>25%</th>\n",
    "      <th>50%</th>\n",
    "      <th>75%</th>\n",
    "      <th>max</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>campaign</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>TVC01</th>\n",
    "      <td>6185.0</td>\n",
    "      <td>34.019688</td>\n",
    "      <td>9.535905</td>\n",
    "      <td>0.007</td>\n",
    "      <td>28.080</td>\n",
    "      <td>33.15</td>\n",
    "      <td>38.8500</td>\n",
    "      <td>120.2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>TVC02</th>\n",
    "      <td>6708.0</td>\n",
    "      <td>46.696394</td>\n",
    "      <td>13.213402</td>\n",
    "      <td>12.950</td>\n",
    "      <td>38.010</td>\n",
    "      <td>45.61</td>\n",
    "      <td>54.2125</td>\n",
    "      <td>115.4</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>TVC03</th>\n",
    "      <td>8331.0</td>\n",
    "      <td>43.795541</td>\n",
    "      <td>14.033336</td>\n",
    "      <td>8.250</td>\n",
    "      <td>33.995</td>\n",
    "      <td>42.48</td>\n",
    "      <td>51.8800</td>\n",
    "      <td>119.5</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../Figures/Part_1_ETL_Field_Fig3.png\" height=\"500px\"></center>\n",
    "\n",
    "<center>Figure: Snow depth distributions for each of the intensive campaigns (November, January and March) for the 2018/19 winter season</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute summary site statistics\n",
    "We match sites with the magnaprobe data to compute summary statistics. Distance between the magnaprobe points and the snow pit are also calculated to make sure we are on target. We then take the reference SSA, density, and temperature datasets to generate layer weighted averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_stats = pd.DataFrame()\n",
    "for idx, pit in pit_meta.iterrows():\n",
    "    mp_local = mp_utm.loc[mp_utm['site'] == pit['site']]\n",
    "    pit_local = gpd.GeoSeries(pit.geometry, crs = constants.CRS_UTM8N)\n",
    "    dist_to_pit = mp_local.geometry.apply(lambda g: pit_local.distance(g))\n",
    "    \n",
    "    snow_stats = pd.concat([snow_stats,pd.DataFrame({'site': [pit['site']],\n",
    "                  'depth_count': [mp_local['depth'].count()],\n",
    "                  'depth_mean': [mp_local['depth'].mean()], \n",
    "                  'depth_median': [mp_local['depth'].median()],\n",
    "                  'depth_std': [mp_local['depth'].std()],\n",
    "                  'dist_max': [dist_to_pit.max()[0]],\n",
    "                  'dist_min': [dist_to_pit.min()[0]],\n",
    "                  'dist_mean': [dist_to_pit.mean()[0]]})],ignore_index=True)\n",
    "\n",
    "# Get weighted mean of each site density ssa and temperature profile\n",
    "for site in snow_stats['site'].unique():\n",
    "    l_ssa = ref_ssa.loc[ref_ssa['site'] == site]['ssa'].values\n",
    "    l_thickness_ssa = np.abs(np.diff(np.append(ref_ssa.loc[ref_ssa['site'] == site]['height'].values, 0)))\n",
    "    snow_stats.loc[snow_stats['site'] == site, 'ssa_mean'] = np.average(l_ssa, weights = l_thickness_ssa)\n",
    "    snow_stats.loc[snow_stats['site'] == site, 'ssa_count'] = len(l_thickness_ssa)\n",
    "    \n",
    "    l_dens = ref_rho.loc[ref_rho['site'] == site]['density'].values\n",
    "    l_thickness_dens = np.abs(np.diff(np.append(ref_rho.loc[ref_rho['site'] == site]['height'].values, 0)))\n",
    "    snow_stats.loc[snow_stats['site'] == site, 'dens_mean'] = np.average(l_dens, weights = l_thickness_dens)\n",
    "    snow_stats.loc[snow_stats['site'] == site, 'dens_count'] = len(l_thickness_dens)\n",
    "    \n",
    "    # Limit to measurements in snow only\n",
    "    ref_temp_snow = ref_temp.loc[(ref_temp['site'] == site) & (ref_temp['type'] == 'snow')]\n",
    "    l_temp = ref_temp_snow['temperature_k'].values\n",
    "    l_thickness_temp = np.abs(np.diff(np.append(ref_temp_snow['height'].values, 0)))\n",
    "    snow_stats.loc[snow_stats['site'] == site, 'temp_mean'] = np.average(l_temp, weights = l_thickness_temp)\n",
    "snow_stats['swe_mean'] = snow_stats['depth_mean']/100 * snow_stats['dens_mean']\n",
    "\n",
    "snow_stats.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>site</th>\n",
    "      <th>depth_count</th>\n",
    "      <th>depth_mean</th>\n",
    "      <th>depth_median</th>\n",
    "      <th>depth_std</th>\n",
    "      <th>dist_max</th>\n",
    "      <th>dist_min</th>\n",
    "      <th>dist_mean</th>\n",
    "      <th>ssa_mean</th>\n",
    "      <th>ssa_count</th>\n",
    "      <th>dens_mean</th>\n",
    "      <th>dens_count</th>\n",
    "      <th>temp_mean</th>\n",
    "      <th>swe_mean</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>RS01</td>\n",
    "      <td>348</td>\n",
    "      <td>34.703563</td>\n",
    "      <td>33.765</td>\n",
    "      <td>7.216446</td>\n",
    "      <td>228.342479</td>\n",
    "      <td>4.151556</td>\n",
    "      <td>83.327945</td>\n",
    "      <td>19.821297</td>\n",
    "      <td>6.0</td>\n",
    "      <td>198.923077</td>\n",
    "      <td>10.0</td>\n",
    "      <td>258.716660</td>\n",
    "      <td>69.033396</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>RS02</td>\n",
    "      <td>288</td>\n",
    "      <td>35.326840</td>\n",
    "      <td>34.390</td>\n",
    "      <td>8.756437</td>\n",
    "      <td>157.222222</td>\n",
    "      <td>1.597891</td>\n",
    "      <td>68.399205</td>\n",
    "      <td>17.792863</td>\n",
    "      <td>5.0</td>\n",
    "      <td>171.207547</td>\n",
    "      <td>8.0</td>\n",
    "      <td>259.609988</td>\n",
    "      <td>60.482217</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>RS03</td>\n",
    "      <td>249</td>\n",
    "      <td>35.454819</td>\n",
    "      <td>34.530</td>\n",
    "      <td>8.763020</td>\n",
    "      <td>162.440222</td>\n",
    "      <td>2.861935</td>\n",
    "      <td>71.542305</td>\n",
    "      <td>21.571987</td>\n",
    "      <td>7.0</td>\n",
    "      <td>206.333333</td>\n",
    "      <td>9.0</td>\n",
    "      <td>262.199997</td>\n",
    "      <td>73.155110</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>RS04</td>\n",
    "      <td>249</td>\n",
    "      <td>32.437510</td>\n",
    "      <td>31.420</td>\n",
    "      <td>7.040102</td>\n",
    "      <td>182.928065</td>\n",
    "      <td>0.983085</td>\n",
    "      <td>78.184670</td>\n",
    "      <td>23.773703</td>\n",
    "      <td>6.0</td>\n",
    "      <td>189.945455</td>\n",
    "      <td>8.0</td>\n",
    "      <td>260.189999</td>\n",
    "      <td>61.613576</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>RS05</td>\n",
    "      <td>280</td>\n",
    "      <td>36.698964</td>\n",
    "      <td>36.095</td>\n",
    "      <td>8.458829</td>\n",
    "      <td>172.568529</td>\n",
    "      <td>2.032063</td>\n",
    "      <td>70.086874</td>\n",
    "      <td>18.298919</td>\n",
    "      <td>6.0</td>\n",
    "      <td>195.764706</td>\n",
    "      <td>8.0</td>\n",
    "      <td>258.889999</td>\n",
    "      <td>71.843619</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract information from external datasets\n",
    "For each site we extract terrain and vegetation information at each site from:\n",
    "\n",
    "- [Grünberg and Boike (2019). Vegetation map of Trail Valley Creek](https://doi.pangaea.de/10.1594/PANGAEA.904270)\n",
    "- [Anders, et al. (2018). Airborne Laser Scanning (ALS) Point Clouds of Trail Valley Creek)](https://doi.pangaea.de/10.1594/PANGAEA.894884)\n",
    "\n",
    "The resulting dataset contains numpy masked arrays of veg height, veg type, and surface elevation for all grid cells within 50 m of all sites. \n",
    "\n",
    "Then generate summary statistics for each site with output variables (*aux_stats*):\n",
    "\n",
    "- **site**: ECCC site names\n",
    "- **pit_ts**: Timestamp of snow pit\n",
    "- **veg_c_per**: Percentage coverage of each veg class in constants.VEG_CLASS\n",
    "- **veg_h_mean**: Mean veg height\n",
    "- **veg_h_std**: Standard dev of veg height\n",
    "- **dem_h_mean**: Mean DEM height\n",
    "- **dem_h_std**: Standard dev of DEM height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_ext = pd.concat([pit_meta,pd.DataFrame(columns=ext_file_var)])\n",
    "for site_idx, site in pit_meta.iterrows():\n",
    "    buffer = site.geometry.buffer(constants.SITE_BUFFER)\n",
    "    for var_idx, ext_file in enumerate(ext_file_list):\n",
    "        with rasterio.open(ext_file, \"r+\") as src:\n",
    "            out_image, out_transform = rasterio.mask.mask(src, [mapping(buffer)], crop=True)\n",
    "            out_image = np.ma.masked_where((out_image == -9999)|(out_image == 9999), out_image)\n",
    "            pit_ext.iat[site_idx, pit_ext.columns.get_loc(ext_file_var[var_idx])] = out_image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the veg and dem metrics\n",
    "# TODO: Add masked gradient for slope\n",
    "aux_stats = pd.DataFrame()\n",
    "for idx, pit in pit_ext.iterrows():\n",
    "    veg_cover = [0] * len(constants.VEG_CLASS)\n",
    "    veg_ext = pit['veg_type'][pit['veg_type'].mask == False].data\n",
    "    (veg_type, veg_count) = np.unique(veg_ext, return_counts=True)\n",
    "    veg_per = (veg_count/veg_count.sum())*100\n",
    "    for i,vtype in enumerate(veg_type):\n",
    "        veg_cover[vtype] = veg_per[i]\n",
    "\n",
    "    veg_h_mean = pit['veg_height'].mean()\n",
    "    veg_h_std = pit['veg_height'].std()\n",
    "\n",
    "    dem_h_mean = pit['dtm_elv'].mean()\n",
    "    dem_h_std = pit['dtm_elv'].std()\n",
    "    \n",
    "    dem_s_mean = np.mean(pit['dtm_slope'])\n",
    "    dem_s_std = np.std(pit['dtm_slope'])\n",
    "    \n",
    "    aux_stats = pd.concat([aux_stats,pd.DataFrame({'site': [pit['site']],\n",
    "                                   'pit_ts': [pit['timestamp']],\n",
    "                                   'veg_c_per': [veg_cover],\n",
    "                                   'veg_h_mean': [veg_h_mean],\n",
    "                                   'veg_h_std': [veg_h_std], \n",
    "                                   'dem_h_mean': [dem_h_mean],\n",
    "                                   'dem_h_std': [dem_h_std],\n",
    "                                   'dem_s_mean': [dem_s_mean],\n",
    "                                   'dem_s_std': [dem_s_std]})],ignore_index=True)\n",
    "# Merge the aux and snow stats for each site\n",
    "pit_stats = pd.merge(aux_stats, snow_stats, on='site')\n",
    "pit_stats.to_csv(\"../Data/pit_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average site composition\n",
    "cum_cov = [sum(x) for x in zip(*pit_stats['veg_c_per'].values)]\n",
    "cum_elm = len(pit_stats['veg_c_per'])\n",
    "avg_cov = [i / cum_elm for i in cum_cov]\n",
    "print(constants.VEG_CLASS)\n",
    "print(avg_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the extracted data\n",
    "site_name = 'RS26'\n",
    "site_analysis = pit_ext[pit_ext['site'].str.contains(site_name)]\n",
    "site_aux = aux_stats[aux_stats['site'].str.contains(site_name)]\n",
    "site_snow = snow_stats[snow_stats['site'].str.contains(site_name)]\n",
    "print('Site {}'.format(site_name))\n",
    "print('Mean MP Snow (cm): {:.3}'.format(site_snow['depth_mean'].values[0]))\n",
    "print('Weighted Cutter Dens.: {:.4}'.format(site_snow['dens_mean'].values[0]))\n",
    "print('Mean SWE (mm): {:.4}'.format(site_snow['swe_mean'].values[0]))\n",
    "print('Mean IC SSA: {:.3}'.format(site_snow['ssa_mean'].values[0]))\n",
    "print('Mean Veg. Height: {:.2} m\\n'.format(site_aux['veg_h_mean'].values[0]))\n",
    "for vi, vc in enumerate(constants.VEG_CLASS):\n",
    "    print('{}: {}%'.format(vc, np.round(pit_stats['veg_c_per'].values[0][vi],1)))\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 10))\n",
    "ax1.imshow(site_analysis['veg_type'].values[0])\n",
    "ax2.imshow(np.log(site_analysis['veg_height'].values[0]* 200))\n",
    "ax3.imshow(site_analysis['dtm_elv'].values[0])\n",
    "\n",
    "ax1.set_title('Veg. Type')\n",
    "ax2.set_title('Veg. Height')\n",
    "ax3.set_title('Elevation')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Site RS26  \n",
    "Mean MP Snow (cm): 41.8  \n",
    "Weighted Cutter Dens.: 227.7  \n",
    "Mean SWE (mm): 95.11  \n",
    "Mean IC SSA: 15.1  \n",
    "Mean Veg. Height: 0.03 m  \n",
    "\n",
    "Tree: 0%  \n",
    "Tall Shrub: 0%  \n",
    "Riparian Shrub: 0%  \n",
    "Dwarf Shrub: 0%  \n",
    "Tussock: 0%  \n",
    "Lichen: 100.0%  \n",
    "Water: 0%  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../Figures/Part_1_ETL_Field_Fig4.png\" height=\"500px\"></center>\n",
    "\n",
    "<center>Figure: Example of vegetation type, height and DSM elevation for site RS26</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the processed field datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_meta.to_pickle(\"../Data/site_meta.pkl\")\n",
    "ref_ssa.to_pickle(\"../Data/ref_ssa.pkl\")\n",
    "ref_rho.to_pickle(\"../Data/ref_rho.pkl\")\n",
    "ref_temp.to_pickle(\"../Data/ref_temp.pkl\")\n",
    "mp_utm.to_pickle(\"../Data/ref_mp.pkl\")\n",
    "pit_meta.to_pickle(\"../Data/ref_pit.pkl\")\n",
    "pit_stats.to_pickle(\"../Data/pit_stats.pkl\")\n",
    "pit_ext.to_pickle(\"../Data/pit_aux.pkl\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "185abe9aacfaffbdd0776bef2c60283fe6f7b5899d78c36d60025b7ba6d63b34"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
